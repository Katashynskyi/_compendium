

# Tech interview

## !Види завдань в ML? (5шт)

1. Класифікація
2. Регресія
3. Кластеризація
4. Зменшення розмірності
5. Виявлення аномалій.

## !В чому різниця supervised, semi-supervised, unsupervised?

1. supervised- данні розмічені\є ground truth (labeled)
2. unsupervised - нерозмічені\без ground truth (unlabeled)
3. semi-supervised - спочатку треба дорозмітити через unsupervised technics а потім навчити через supervised.

## ! Які є види завдань в ML? (більш детально)

1. Класифікація (supervised).
  * Розмічені дані фотографій котів\собак\півнів. Результат: здебільшого правильне передбачення тварин.
2. Регресія (supervised).
  * Target: price. Features: дані квартир. Predict: Price
3. Кластеризація (unsupervised)
  * У маркетингу поділяє покупців на кластери для створення персоналізованих пропозицій для формування ціни, нових позицій товарів, своєчасних знижок.
4. Зниження розмірності (unsupervised)
  * Передує завданням регресії, класифікації, кластеризації, зменшуючи кількість фіч і створюючи власні не інтерпретовані фічі, інколи зводячи їх кількість до 2-х, 3-х для візуалізацій.    
5. Навчання з підкріпленням (невизначене)
  * принцип работы???
  * боты в играх (шахматы, Го, пакман)
  * трейдинговый бот
  * робот-манипулятор 
  * диалоговые чатботы


## ! Які є алгоритми класифікації?
1. Описати на пальцях. 
2. Знати різницю між decision tree та random forest
3. У чому плюси та мінуси алгоритмів.

### !Logistic regression
Logistic regression - алгоритм прогнозування ймовірності бінарної події через порівняння з логістичною кривою.
  * feature scaling не обов′язковий.
  * Низька perfomance з нелінійними даними.
  * слабенький 
  * у лінійній регресії результат безперервний вага\зріст\час. В ЛогРег. - має обмежену кількість результатів - так\ні, вино\пиво, правда\брехня. 
  * насправді не регресія, а метод класифікації
  * багато класифікаторів, після невеличкого тюнінгу, перетворюються на регресори. 
    * Наприклад, ми можемо не просто вирішити, до якого класу належатиме об'єкт, а й запам'ятовувати, наскільки — і ось у нас регресія.
---
Нова машина коштує 20к з кожним роком ціна падає на 1к, покупець має 10к, класифікатор відповідає на запитання, чи буде 10 річна машина коштувати 10к?

### !SVM
Машина опорних векторів (SVM) - А. підвищує розмірність векторів і шукає роздільну гіперплощину з найбільшим зазором (margin).
* +вважається кращим з усіх лінійних класифікаторів
* завзяки максимізації полоси між класами краще узагальнює, й відносно легко можна модернізувати не лінійним ядром. 
* +стійкий до викидів
  * добре підходить для спам-фільтрів(пошук викидів)
* +легка, швидко навчається.
* -не підходить для великих наборів даних
* -якщо features більше ніж samples - погано прогнозує.
* -погано спрацює на зашумлених даних
* -погано спрацює якщо дані будуть overlap.
* -не має вбудованого відбору ознак на кшталт L-1 регуляризатора (можна додати окремо) 
* дані рідко можна розділити лінійно (гіперплощиною), тому всі дані вкладають у простір з підвищеною розмірністю ще й так, щоб дані стали лінійно розділені (kernel trick).
    * polynomial kernel
    * radial kernel (RBF radial basis function
* класифікатор RVM Relevance Vector machine - ще й повертає probability з якою спостереження належить до певного класу.
---
just right drugdose  дозуваня можна визначити звівши в квадрат й провівши SV classifier лінію. Рідко спрацьовує, тому радше використовують kernel trick.

### naive Bayes
naive Bayes (multinomial N B classifier а не gaussian N B classification) - простий А. класифікації заснований на теоремі Байєса.

  * Перевірка листа на спам: Навчання - Беруть розмічені листи - спам\не спам і рахують в них кількість слів (bag of words якийсь...). Высчитывают вероятность встречаемости слова во всех не спам письмах / все не заспамленные слова, то же вычисляем для спама. Какая вероятность выше к тому классу скорее всего и пренадлежит слово. Потом все вероятности слов из письма переумножаются отдельно для спама и неспама. Если вероятность выше в класе спам - значит письмо спам, и наоборот.
    * чтобы не было 0 в вероятностях, используют +1 к каждому классу.
    * Байес наивный потому что не видет порядка слов.
    * has high bias (предвзятость) & low variance (разброс)
    * отравление байеса, добавление в конец письма слов с хорошим рейтингом.

### Наивный Байес - каверзный вопрос.
Есть алгоритм наивный байес и определение вероятности по Байесу.
Есть ещё Калмогорово определение вероятности которое более правильное. 
Калмагоровская вероятность более взрослое определение вероятности, он развивал намного более сложные вещи. 
  * в физике ты пишешь обычные формулы а потом узнаёшь что это градиент. Производная вводится, более взрослое описание мира. 

Идея\ключ наивного Байеса - есть условная вероятность  и во всех алгоритмах предполагается что мои фичи независимы между собой.  
С точки зрения вероятности - у нас есть два независимых события и их мы можем перевести в произведение.

### !Decision tree
decision tree - один А. що приймає рішення.
* А. будує багато бінарних запитань/відповідей так\ні: більше х(умова) - праворуч, менше - ліворуч.
* чим вище рівень тим більш загальне питання
  * Gini impurity визначає яка фіча буде ближче до root'у
* працює з yes\no data, numerical data (weight), ranked data (range(1,4))
* дереву рішень на зміну прийшов ансамбль дерев, які бува кращі нейромереж.
* +менше зусиль для підготовки даних
  * NaN не впливають
  * outliers не впливають
* +не потребує нормалізації та scaling'у даних
* -мала зміна в даних призведе до великих змін в алгоритмі (High Variance).
* -дає низьку точність прогнозу
* -складний, довго навчається
* -схильні до overfit'у, треба обрізати (pruning)
* -не підходить для регресій.
---
коли банк не хоче сліпо вірити машині у питанні повернення клієнтом кредиту й потрібно інтерпретувати\обгрунтувати машинну модель.

### Random forest 
Random forest - т.н. bagging (Bootstrap AGGregate) trees.
* -- inaccuracy - неточные
* -+ хороши в train data но плохи в test data

* Суть всех этих алгоримов - у меня появляется условное голосование. Не один алгоритм принятия решений а несколько, которые голосуют, ансамбль алгоритмов.
* bootstrap algorithm - выбираем сэмплы (1 string with all features) случайным образом, можно повторяться получаем bootstraped dataset. 
  * out-of-bag dataset - 1\3 даты что не попала в bootstrap dataset - become validation dataset
* строим 100 (ideally) деревьев со случайным выбором root node, на 2,3 уровень нод тоже случайно выбираем фичи.
* вариативность делает его эффективным 
Бустинговые деревья: XGBoost, CatBoost, LightGBM 

Когда есть итерации алгоритмов, постепенно улучшаешь (boost).
Тренируя на выборке одно дерево мы делаем ошибки, тренеруя следующее маленькое дерево мы минимизируем эту ошибку.

## !Які є метрики класифікації?

!Accuracy - точність прогнозу, вона узагальнює всю-всю матрицю помилок, щоб працювало треба збалансовані данні.

TP+TN/TP+TN+FP+FN: %age correct predictions
* метрика не враховує FN&FP
* щоб працювало треба збалансовані данні.

!Precision - правильність якщо нас цікавить співвідношення правильно вгаданих до всіх правильних. 

TP/TP+FP: Високий Precision дозволить мінімізувати кількість операцій, не наймати сортувальників, не засмучувати шефа.
* FP - помилка 1-го роду
* В класифікації залежить від threshold

!Recall (sensitivity) - чуттєвість. Високий FN дозволить закінчити епідемію, уникнути суду за авторські права ляльки, вкластись в дедлайн.

TP/TP+FN: коли ми зважаємо на наслідки (не можна лажати, мінімізувати ризики).
* FN - помилка 2-го роду
* В класифікації залежить від threshold

!F1 - поєднання Precision & Recall.
* якщо Precision & Recall однаково важливі.

ROC | AUC (receiver operating characteristic)

ROC graph summarizes all of the confusion matrices that each threshold produced. In classification from 0 to 1
* в класифікації не залежать від threshold

## !Приклади метрик класифікацій (тільки precision recall (дописати))

В дизайнерському бюро 10 проектів.
Які брати на ретроспективу а які лишити, якщо настрій у шефа поганий? (значить не показувати фігню | засмутиться).
TP - принесли зайшло | вклались в дедлайн.
TN - не принесли фігню | шеф не засмутиться.
FP - принесли фігню | шеф засмутиться.
FN - забули скинути готовий проект.| прогавити дедлайн.
Precision: акцент на FP (якщо нам важливо не засмутити шефа) > Recall: акцент на FN (якщо нам важливо встигнути в дедлайн).

Є 100 ляльок, кожна 5-та порушує авторські права.
Треба звертату увагу на Precision чи Recall щоб ляльки відсіювались ще на заводі? (ціль: не піти під суд)
Precision: акцент на FP (ловимо ляльки в на заводі | сортувальників не наймаєм) < Recall: акцент на FN (назбирається багато ляльок на заводі| доведеться наймати сортувальників)

Є 100 ляльок, кожна 5-та з недомальованими очима.
Треба звертату увагу на Precision чи Recall щоб пропускати брак і довірити повернення магазинам? (ціль: зекономити)
Precision: акцент на FP (ловимо ляльки в на заводі | сортувальників не наймаєм) > Recall: акцент на FN (назбирається багато ляльок на заводі| доведеться наймати сортувальників)

В місті епідемія, щоб її зупинити треба відрізати великий палець на правій руці всім інфікованим, або той помре через 24 години. Є два тестери Precision\Recall 80\60 та Precision\Recall 60\80.
Які тестери роздати медикам щоб зупинити епідемію, з вищим Precision чи Recall? (ціль: зупинити епідемію).
Precision: акцент на FP (сконцентруватися на відрізанні пальців) < Recall: акцент на FN (знайти максимальну кількість інфікованих)
Якщо епідемія не смертельна, то спочатку зважаємо щоб більше люду лишилося з пальцями.

## !Як боротись з unbalanced класами? Resampling

* правильно обрати метрику.
* stratify при (train test split)
* K-fold cross validation (тільки перед over-sampling, а не після)
* 10 ansemble models:
  * logistic regression & random forest мають тенденцію до узагальнення, відкидаючи rare class.
  * 1k rare data are used in each model.
  * 10k abundant data splittet on 10 pieces.
* 10 ansemble models:
  * різне співвідношення (rare:abundant) 1:3, 2:1 etc. Залежно від моделі, може вплинути на weight того чи іншого класу та на голосування загалом.
  
* доповнити дані(Over-sampling).
  * зкомбінувати зі схожим датасетом.
  * augmentation в картинках.
  * SMOTE lib - генерація синтетичних даних.
  * repetition?
  * bootstrapping?
* видалити дані (Under-sampling).
  * тільки якщо трішки.
  * ???могу удалить признаки для нулевого класса и у меня остануться сбалансированные???

* в текстах я настраиваю с помощью весов, определённым способом настроить нейронную сеть. В деревьях это гиперпараметром, как добавить привилегию одного класса перед другим, то есть модель будет получать больше штраф - как называется этот штраф? взвешенные... ??

## Які є алгоритми кластерізації?

## Які є метрики кластеризації?

## Overfit & Underfit. Що це, пов′язані проблеми, як їх визначити?

При навчанні алгоритму, ціль training data це знайти залежності. Пухнаста, значить кішка. Коли модель бачить тестові дані вона проектує те що було в трейні (крок в крок).
* overfit (aka variance) - модель за всіма features, намагається захопити кожну деталь, кожну дрібницю.
  * при навчанні на картинках коргі раптово подати круасан - модель розпізнає її як собаку. Втрачається здатність до узагальнення (generalization)
* underfit (aka bias) - навпаки, ще треба донавчати, бо навіть коргі від решти класів не відрізняє.
---
Визначаємо overfit & underfit .
* Його видно в метриках, loss accuracy, неважливо. 
* Train: 40 test: 60 => underfit треба ще донавчити.
* Train: 60 Test: 40 => overftit перенавчено.


## !Як боротись з перенавчанням й недонавчанням?

* В naive Bayes, logistic regression, SVM.
  * спростити layers & parameters моделі.
  * змінити гіперпараметри.
* В decision tree, random forest 
  * pruning (підстригти)
* Lasso regr, regr.
  * додати penalty за великі weights(regularization)
* В ANNs можна змінювати параметри & layers тобто архітектуру, а ще покрутити гіперпараметри моделі.
    * dropout "проріджування\виключення" 
      * якщо loss function не змінюється, то мережу треба продовжувати спрощувати. 
    * зменшувати № of layers
    * ???задаём процент вероятности с которым какой-то слой будет занулятся, посмотри зачем это делается. ???

## Що зробити, щоб не було оверфіту?

* можем добавить данных (модель будет тренироваться дольше)
* сделать проще, убрать кол-во параметров и фичей
* чтобы убрать кол-во фичей можно использовать методы регуляризации
* понижение размерности

## Overfit & underfit. Что такое Bias & variance?

* Когда в train выборке score выше  чем в validation выборке, значит модель чересчур хорошо подстроилась под обучающие данные, это overfit.
* Когда train score = 40% а test score = 80% значит??? есть ещё куда расти - underfit
  * Хорошая модель имееет низкий bias и низкий variance

* bias - предвзятость. В линейной регрессии всегда будет высокий bias т.к. она не может изогнуться в кривую.

* variance - дисперсия, разброс - линейная регрессия будет иметь маленькую дисперсию т.к. сумма квадратов будет очень похожей для разных датасетов.

## !Що таке регулярізація? L1, L2, Elastic net? Різниця, як обрати? Dropout?

### !Регуляризація 
Регуляризація, комплекс заходів спрямованих на те, щоб модель не перенавчалася.
Часто модель навчається на зашумлених даних + в fine-tuning інакший датасет + data drifting. Для узагальнення моделі ми штрафуємо її за складність, шукаючи баланс між bias\variance через гіперпараметр λ.



↓ Pred починає сильно розходитись з train (сплеск) коли апроксимуємо поліномом дуже високої степені (50-ї).
* Треба зменшити складність ф-ії, тобто кількість фічей (feature space), процес цей ще називається feature extraction.
* при перенавчанні в ANNs не можливо зменшити кількість features та layers (поламаємо енграми) але можна прикріпити регуляризацію.



Регулярізація - додаткові обмеження для weights (штрафи). Коли ANNs weights одних нейронів дуже переважають над іншими, регулярізація ці переваги нівелює.
* l1 регуляризація (LASSO, least absolute shrinkage and selection operator), враховуєм $||w||_1$ - коеф. ваги
  * коефіцієнти інколи зкочуються в 0.
  * L1 використовують для feature selection, можна відкинути будь-які змінні, пов’язані з коефіцієнтами, що прямують до нуля.
  * підходить для sparse data.
* l2 регуляризація (Ridge), враховуєм $||w||^2_2$
  * незалежні змінні зменшуються, рівномірно близько до 0.
  * використовують для collinear/codependent features.
* Elastic net - комбо цих двох.



[difference](https://explained.ai/regularization/L1vsL2.html)

### !Dropout
"проріджування\виключення" - один із методів регуляризації (тільки в ANNs). Зв'язки між нейронами у випадковому порядку вимикаються, підвищується ймовірність того, що сигнал буде перерваний, є одним із ключових у боротьбі з перенавчанням, та підвищує його швидкість.



* regularization, boosting, bagging - методы для поиска хорошего алгоритма между простой и сложной моделью.

## Що робити з пропусками в даних?

посмотреть методы заполнения данных.
  * всегда могу удалить
  * можно заполнить самым повторяющимся числом.
  * можно заполнить средним.
  * если это страны, можно внести класс Other
  * а можно сделать хитро, сделать кластеризацию и посмотреть в какие кластеры это пустое поле попадает. Либо по отношению к таргету построить такую статистику. Или в scikit-learn есть inputer, более продвинутый из этой серии.
 
 2. precision если важна точность - можно что-то пропустить  но если говорит что первый класс - то это железобетонный первый класс.
 3. recall - покрывать все классы\ лейблы.
 4. f1 - их комбинация

## Все классификаторы возвращают score - вероятность принадлежности определённых данных к определённому класу. Как его превратить в класс?

## какую метрику буду выбирать на том или ином тесте?

* проходячи через threshold 0.5 (ANNs це ф-ія активації)
У мене є умовна розділяюча площина, якою я розділяю на класи, threshold можна змінювати. Класифікатор повертає вірогідність 1 або 0.

## Какие алгоритмы регрессии ты знаешь?

скопіюй й доповни з класифікаційного SVMa

### Какие метрики регрессии ты знаешь?

[ссылка](https://getpocket.com/read/2993397662)


Для алгоритмов машинного обучения не существует универсальной функции потерь.

Выбор функции потерь для конкретной задачи зависит от различных факторов, таких как тип выбранного алгоритма машинного обучения, простота вычисления производных и, в некоторой степени, процент выбросов в наборе данных. 

---
Regression Losses: MSE, MAE, MBE or L1 loss, L2 loss and MBE. 
# R2 R2 улучшенный???
# L1 L2 это к регуляризации?? 
---
**Mean Square Error/Quadratic Loss/L2 Loss**  
1. differences = predictions - targets
2. differences_squared = differences ** 2
3. mean_of_differences_squared = differences_squared.mean()
4. rmse_val = np.sqrt(mean_of_differences_squared)
5. return rmse_val 
---
**Mean Absolute Error/L1 Loss**
1. def mae(predictions, targets):
2. differences = predictions - targets
3. absolute_differences = np.absolute(differences)
4. mean_absolute_differences = absolute_differences.mean()
5. return mean_absolute_differences
---
**Mean Bias Error** (редко) т.к. может загнать рез-ат в минус

---
**Classification Losses: SVM loss, Cross entropy loss(LogLoss)**
---
1. Hinge Loss/Multi class SVM Loss

2. Cross Entropy Loss/Negative Log Likelihood An important aspect of this is that cross entropy loss penalizes heavily the predictions that are confident but wrong

---

[ссылка на статью](https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23)

### Пример
1. Цена за дом 300, модель запрогнозирована на 350, 
  * Первая метрика - нужно от первого отнять второе. И взять в модуль, чтоб не зависило вверх это или вниз, какая разница ошибки модели.

## Зачем данные разбивать на выборки и на какие выборки их разбивать?

* не говорить о процентах в разбиении. 
* зачем мне эти сеты?
  * train dataset - тренирую модель (строим отношение между Х и y), паралельно её улучшая, меняя гиперпараметры, параметры (архитектуру).
    * по факту, каждый набор гиперпараметров это и есть модель.
  * validation dataset нужен чтобы проверить качество модели с трейна используя новые данные. 
  * test dataset используют для констатации метрик, score.
    * под неё подгонять нельзя,можно получить leakage данных.
    * test - использовать только несколько раз . 
    * хорошо когда ещё есть продакшн тестирование. Заводим в прод и проводим тестирование.
   
  * кросс валидация - идея в том чтобы не быть зависимым от случайности. Разбиение на трейн валидацию тест - всё случайно, и в трейн могут попасть хорошее в тест плохое, и если их поменять местами то точность упадёт. Для этого и придумали кросс валидацию, чтобы уйти от этой зависимости. 
  * есть способы разбития на тест\трейн в  sklearn.split() чтобы какой-то класс был равномерно представлен. К примеру относительно таргета разбивать. Чтобы не получились разбалансированные классы, в тест все единички, в тест все нолики
  * посмотреть стратегии разбиения на тест\трейн холды(Hold-Out Validation)
  * в кросс валидации тоже есть стратегия разбиения и определения крос фолдов
  * разбил на тест (тест отложенный) а трейн с вадилацией обьёмом в 90% данных по разному разбиваю чтоб получилось 10 разных моделей и 10 результатов на валидации. Могу усреднить и посмотреть какая модель работает в среднем, и на этом сете я могу выбрать идеальный сет гиперпараметров.

### графік



## Какие алгоритмы понижения размерности я знаю?

Если две точки и 10 фичей\пространств И когда они рядом то при понижении размерности они тоже остаются рядом. Понизив до 2д и 3д я могу сделать визуализацию 
* PCA - линейный , позволяет делать линейные преобразования моих данных в некоторое пространство пониженной размерности. 
* t-sne - нелинейные
* u-map - нелинейные

## !Feature selection & Feature importance (подолати прокляття розмірності).

апріорне й апостеріорне: вибір оптимальної кількості колонок враховуючи correlation matrix. З низькою кореляцією лишаємо, з високою оптимізуємо чи видаляємо.
* лишив релевантні фічі - модель швидко й добре навчиться.

апостеріорне: Feature importance calculates score після навчання й допоможе викинути неважливі фічі зменшивши розмірність моделі
lime & shap for blackbox ANNs
є також і в інших видах алгоритмів (дописати)

их можно и при построении датасета подбирать и уже когда построил модель. 
* нужно брать признаки на которых модель будет быстро обучаться и они будут самые релевантные 
* почему коррелируемые признаки это плохо?
  * ???когда смотрим на построение логистической регрессии, необходимо брать обратную матрицу, а для неё нужно посчитать детерминант, и у коррелируемых фичей детерминант 0, там детерминант стоит в знаменателе, у меня будет деление на 0, алгоритм не будет работать.???

## Feature engineering?

*

## Что такое корреляция и ковариация?

* ковариация - это про ковариационную матрицу.
* корреляция (co-relate - со-зависимость)- мера линейной зависимости двух или более величин. Изменение одной сопровождается изменением другой (остальных).
  * когда растёт рождаемость - растёт и экономика
  * когда две вещи скоррелируемые мы можем построить линейную зависимость (когда одно растёт и второе растёт, или одно растёт второе падает). Но это не значит что одно зависит от другого.

## В деревьях есть feature importance, 3 шт (почитай)
  * они помогают отобрать релевантные признаки
Есть ещё библиотеки LIME и SHAP-values. 
* они помогают понять модель
* можно проанализировать как входные данные влияют на поведение самой модели 
  * увеличение какого-то признака влияет на неё в целом

## feature selection

про feature selection - могу отбирать фичи в зависимости от метрик. Могу менять модель по разным наборам своих фичей и буду получать разные метрики. 
* есть стратегия
  * либо начинаю с одной фичи и постепенно добавляю
  * либо по одной убираю фичи и смотрю метрики

## Данные могут быть расположены по разному и иногда они могут быть не разделимы. 
* линейная регрессия не работает т.к. данные одного класса находятся внутри другого (два кружочка) 
* невозможно нарисовать линию которая бы разделяла их в двухмерном пространстве, спрашивают про ядра в SVM'e 
  * есть полиномиальное ядро, гаусовское ядро 
  * делаю преобразования исходного  пространства в другое (в проекцию). Проекция это про понижения, а тут про преобразования. 
    * пример: есть полярные координаты, я могу выбирать разные системы координат, разносить свои точки на плоскости сделав небольшие преобразования, что поможет их разделить.

## Оценки качества
Если есть разлейбленные данные, их лейблят люди. Мне нужно оценить хорошо это они сделали или нет
* для этого есть capascore

## Почему аномалии (выбросы) это плохо?

Аномалии стоит выбрасывать чтобы те не усложняли обучение модели. 
Если конечно мне не нужно определять эти аномалии. 
* Есть алгоритмы для определения аномалий 
  * можно threshold'ом вылавливать
  * можно посчитать anomaly detection

### графік



## Зачем нужны активационные ф-ии?
Нейронная сеть - у нас есть на входе данные я их как-то суммирую и умножаю на какой-то вес, повторить на несколько слоёв. Если больше ничего не делать - то это обычные линейные преобразования с алгербы. Ничего не поменяв моя ф-ия остаётся линией. Я смогу решать только линейные задачи, логистическую регрессию. Я не могу перейти в другое пространство. Не могу разделить 2 круга, они не разрешими. 
* для этого используется акт. ф-ия
* узнать +\- их

## backpropagation
* затухание градиентов 
* взрывные градиенты 
в чём причина и почему это плохо?

## Что такое ембединг? Зачем они нужны? Как они строятся? Какие ембединги я знаю?
*Идея NLP - Обьяснить компьютеру слова, как-то тексты перевести в числа. Построить отображение из пространства слов.
Bag of Words, Word2Vec, TF-IDF, FastText, Bert, Elmo, flyer. Это модели которые позволяют преобразовать мои слова в цифры.

## Неочевидні питання.

Могут спрашивать deployment , бизнес задачи, coding и пр.
* нужно популярную задачу решить. и там будет NLP
* классификация ревьюшек, описание модели. В котором попробуем классические техники и прикрутить ещё трансформеры
* попробовать нлп задачи, с классичских ner-o.
* можно заняться text classification, recomendational systems( текстовые и табулярные данные) 
* визуализация данных - нужно отстроить данные и понять что перед тобой, первичный анализ данных, разные визуализации, инсайды поискать. 
* ner - самые популярные задачи в НЛП. 
* в начале я буду работать с табулярными данными. 
* в гите колабовский код сохраняют - это ужасно.

## Gradient descent

ГС - метод нахождения локального минимума (желательно глобального) функции с помощью движения.
Gradient descent used for:
* updating weights of AI model
* minimizing the training loss

example: пилот снижается - с minimization of loss он мастерски будет садиться без outliner'ов (типа перелёт или разбился) и не резко (чтоб ни у кого не болела голова при приземлении)и не рассыпался от перегрузок самолёт.

Perceptron (восприятие) - provides binary prediction, 0 or 1. Has step activation function

Gradient descent - provides decimal prediction from 0 to 1, like .68. Can use planly activation functions, like sigmoid activation functions

Threshold or bias был вмонтирован в step activation function in perceptron
and was like Σ=features * weights.

In Gradient descent it turns to Σ=features * weights+bias

### Ілюстрації





### Perceptron
Персептрон это самая простая модель нейронной сети. 

Наша цель - уменьшить loss, он же cost, он же у-hat, он же error function который в категориальном персептроне (1,0) должен стремиться не только преодолеть threshold в 0.5 но и к значениям близким 0. cross entropy loss это всего лишь одна из loss функций, через которые можно подправить веса и привести y-hat(predict) к y(target) значениям, тем самым улучшая точность модели. 

Регрессия в 19-м веке Френсис Гальтон - дети высоких и низких родителей обычно не наследуют выдающийся рост - феномен "регрессия к посредственности".





### Регрессия
* метод моделирования и анализа отношения между переменными и чтоб посмотреть на результат этих отношений
Есть 5 основных типов регрессии:
* [ссылка на статью](https://medium.com/nuances-of-programming/5-%D0%B2%D0%B8%D0%B4%D0%BE%D0%B2-%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%B8-%D0%B8-%D0%B8%D1%85-%D1%81%D0%B2%D0%BE%D0%B9%D1%81%D1%82%D0%B2%D0%B0-f1bb867aebcb)

### Linear regression
Линейная регрессия (AKA least squares)- простая что позволяет моделировать\анализировать dependency между независимой х и зависимой у с помощью линейной модели, то есть прямой. К ней можно приписать множественную линейную регрессию где много независимых переменных (x_1,x_2,x_3) и одна зависимая у. В многомерном пространстве линию мы рассматриваем как plane на который мы смотрим с торца.
  * используют если данные на визуализации относительно линейны.

Y = a_1*X_1 + a_2*X_2 + a_3*X_3 ……. a_n*X_n + b

a_n — это коэффициенты, X_n — переменные и b — смещение
-все коффициенты линейны и подходят для работы прямой.

* Она легко моделируется и является особенно полезной при создании не очень сложной зависимости, а также при небольшом количестве данных.
* Обозначения интуитивно-понятны.
* Чувствительна к выбросам.

#### ещё
* если обучаем линейную модель нужно избавляться от высокой корреляций, если она увидит одно и то же, то модель переобучится
  * можно оставить 1 признак остальные выкинуть
  * можно признаки выразить через что-то общее (обобщить(
  * сделать нелинейное преобразование для снижения корреляции

### Polynomial regression
Полиномиальная регрессия - кривая. У некоторых переменных есть степень, у других — нет. 

Y = a_1*X_1 + (a_2)²*X_2 + (a_3)⁴*X_3 ……. a_n*X_n + b

Моделирует нелинейно разделенные данные (чего не может линейная регрессия). 

* Моделирует нелинейно разделенные данные (чего не может линейная регрессия). Она более гибкая и может моделировать сложные взаимосвязи.
* Полный контроль над моделированием переменных объекта (выбор степени).
* Необходимо внимательно создавать модель. Необходимо обладать некоторыми знаниями о данных, для выбора наиболее подходящей степени.
* При неправильном выборе степени, данная модель может быть перенасыщена.

### Ridge regression
Гребневая (ridge) регрессия - добавляет penalty для линейной регрессии в виде 
  * y-hat*slope*x=sum of squares residuals (Остаточная сумма квадратов)
  * y-hat*slope*x+lambda*slope^2=regularization
    * чем больше lambda тем меньше x влияет на  предсказание.
    * lambda выбирается через 10-fold cross validation. Где меньше variance (дисперсия\ разброс) такую lambda и выбираем.

### Регрессия по методу «лассо»

### Регрессия «эластичная сеть»

Для алгоритмов машинного обучения не существует универсальной функции потерь.

Выбор функции потерь для конкретной задачи зависит от различных факторов, таких как тип выбранного алгоритма машинного обучения, простота вычисления производных и, в некоторой степени, процент выбросов в наборе данных.

## Regression Losses: MSE, MAE, MBE or L1 loss, L2 loss and MBE.

**Mean Square Error/Quadratic Loss/L2 Loss**  
1. differences = predictions - targets
2. differences_squared = differences ** 2
3. mean_of_differences_squared = differences_squared.mean()
4. rmse_val = np.sqrt(mean_of_differences_squared)
5. return rmse_val 
---
**Mean Absolute Error/L1 Loss**
1. def mae(predictions, targets):
2. differences = predictions - targets
3. absolute_differences = np.absolute(differences)
4. mean_absolute_differences = absolute_differences.mean()
5. return mean_absolute_differences
---
**Mean Bias Error** (редко) т.к. может загнать рез-ат в минус

---
**Classification Losses: SVM loss, Cross entropy loss (LogLoss)**

---
1. Hinge Loss/Multi class SVM Loss

2. Cross Entropy Loss/Negative Log Likelihood An important aspect of this is that cross entropy loss penalizes heavily the predictions that are confident but wrong

---

[ссылка на статью](https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23)

# Старое

## OLDIES (RNNLM) reccurent neural network language model 2003

TF-IDF

BOW

OHE

лемматизация — замена слова его начальной формой (например, “мы бежим” превратится в “я бежать”)

Стеммирование — это обрезание окончания слова, оставление только основы (например, “красного яблока” превратится в “красн яблок”)

## Word embeddings word2vec_skip-gram_CBOW Tomas Mikolov(Czech) Google 2013

WORD2VEC -общее название двух архитектур CBOW и skip-gram, которые в отличии от TF-IDF(term frequency - inverse document frequency) делает реальные векторные представления слов.

CBOW — continuous bag of words, continuous потому, что мы скармливаем нашей модели последовательно наборы слов из текста, a BoW потому что порядок слов в контексте не важен.

Обучение CBOW берём 2 слова до 2 после, и  вектор прогноза(model predict)с помощью вектора ошибки (лосса функции) подгоняем к целевому вектору (actual target 0 or 1). 


Skip-gram “словосочетание с пропуском” предсказывает контекст  слов (вектор контекста) опираясь  на текущее слово. Обучается как и CBOW. SGNS (skip-gram negative sampling) - с добавлением отрицательных сэмплов, 0-ки в целевом векторе, которые вообще не соседи а взяты с потолка, для обучения.



Различные размеры окна подходят для разных задач. Замечено, что меньшие размеры окон (2−15) порождают взаимозаменяемые вложения с похожими индексами (обратите внимание, что антонимы часто взаимозаменяемы, если смотреть на окружающие слова: например, слова «хорошо» и «плохо» часто упоминаются в схожих контекстах). Большие размеры окон (15−50 или даже больше) порождают родственные вложения со схожими индексами. На практике вам часто придётся предоставлять аннотации ради полезного смыслового сходства в вашей задаче. В Gensim размер окна по умолчанию равен 5 (по два слова слева и справа, в дополнение к самому входному слову).

Количество отрицательных образцов — ещё один фактор процесса обучения. Оригинальный документ рекомендует 5−20. В нём также говорится, что 2−5 образцов кажется достаточным, когда у вас достаточно большой набор данных. В Gensim значение по умолчанию — 5 отрицательных образцов.

## Global Vectors (GloVe) stanford 2014

GloVe минимизирует разницу между произведением векторов слов и логарифмом вероятности их совместного появления с помощью стохастического градиентного спуска. Полученные представления отражают важные линейные подструктуры векторного пространства слов: получается связать вместе разные спутники одной планеты или почтовый код города с его названием.

  учитывает совместную встречаемость, а не полагается только на контекстную статистику

Преимущества
* Простая архитектура без нейронной сети.
* Модель быстрая, и этого может быть достаточно для простых приложений.
* GloVe улучшает Word2Vec. Она добавляет частоту встречаемости слов и  опережает Word2Vec на большинстве бенчмарков.
* Осмысленные эмбеддинги.

Недостатки
* остаётся обученной на уровне слов и даёт немного данных о предложении и контексте, в котором слово используется.
* Плохо обрабатывает неизвестные и редкие слова.

## FastText Tomas Mikolov(Czech) уже в фейсбуке 2016

* используются одновременно и skip-gram, и негативное семплирование, и алгоритм непрерывного мешка.
* способна генерировать эмбеддинги для неизвестных слов.
* Относительно простая архитектура: feed-forward, 1 вход, 1 скрытый слой, один выход (хотя n-граммы добавляют сложность в генерацию эмбеддингов).
* Благодаря n-граммам неплохо работает на редких и устаревших словах.

Недостатки
* Обучение на уровне слов: нет информации о предложении или контексте, в котором используется слово
* Игнорируется совместная встречаемость, то есть модель не учитывает различное значение слова в разных контекстах (поэтому GloVe может быть предпочтительнее).

## RNN

ANN яка для передбачення одного значення "завтра", бере дані за сьогодні та summarize дані за вчора. Weights & Biases дублюються. 
Якщо данних багато, то RNN бере inputs всіх днів що є і кожен попередній день впливає на результат наступного, за для передбачення одного дня в майбутньому. 
* Чим більше ми розгортаєм RNN тим складніше її навчати
* Vanishing\exploding gradient problem - кожний наступний sample amplified (посилить) відповідь. 
  * при мінімізації loss function затухаючі та взривні градієнти будуть або вистрибуватимуть з global minimum або не доповзуть до нього.
* щоб побороти gradient problem придумали LSTM



## LSTM

* sigmoid(between 0&1) & Tanh(-1 & 1) activation func (в RNN - ReLU)



## Data mining & data extraction
майнинг - обработка данных, поиск закономерностей, и получение знаний. 
* extraction (извлечение) - это сбор данных с целью сохранения и дальнейшей обработки - скрапинг.